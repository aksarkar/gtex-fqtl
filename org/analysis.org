#+TITLE: fQTL analysis
#+SETUPFILE: setup.org

* Introduction

  We previously fit ~fqtl~ models for 39,998 genes across 44 tissues from GTEx
  (version 6p). Here, we analyze the fitted ~fqtl~ models.

* Setup

  #+BEGIN_SRC emacs-lisp :exports none
    (org-babel-lob-ingest "/home/unix/aksarkar/.emacs.d/org-templates/library.org")
    (add-to-list 'python-shell-completion-native-disabled-interpreters "jupyter")
  #+END_SRC

  #+RESULTS:
  | jupyter | pypy | ipython |

  #+BEGIN_SRC emacs-lisp :exports none
    ;; This is needed to unjam when async tasks fail
    (ob-ipython--dequeue 'ob-ipython--async-queue)
  #+END_SRC

  #+RESULTS:

  #+CALL: ipython3(memory="16G",venv="fqtl") :dir /broad/hptmp/aksarkar/fqtl :exports none

  #+RESULTS:
  : 11772297

  #+NAME: imports
  #+BEGIN_SRC ipython
    import glob
    import itertools as it
    import os.path
    import numpy as np
    import pandas as pd
    import scipy.linalg as sl
    import scipy.special as sp
    import scipy.stats as st
  #+END_SRC

  #+RESULTS: imports
  :RESULTS:
  # Out[1]:
  :END:

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])
    import colorcet
    import matplotlib
    import matplotlib.pyplot as plt
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[2]:
  :END:

  #+BEGIN_SRC ipython
    plt.rcParams['font.family'] = 'Nimbus Sans'
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[3]:
  :END:

* Multi-tissue eQTL mapping
  :PROPERTIES:
  :CUSTOM_ID: gtex
  :END:
** Read the data

   Extract the GTEx univariate summary statistics.

   #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar/fqtl/
     qsub -cwd -V -terse -j y
     cp /broad/compbio/data/GTEx/v6_GTEx_Analysis_2015-01-12/eqtl_data/GTEx_Analysis_2015-01-12_eGenesFiltered.tar.gz .
     mkdir -p egenes-filtered
     tar xf GTEx_Analysis_2015-01-12_eGenesFiltered.tar.gz -C egenes-filtered
   #+END_SRC

   #+RESULTS:
   : 11562455

   Extract the gene expression matrices to get sample sizes.

   #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar/fqtl
     qsub -cwd -V -terse -j y
     cp /broad/compbio/data/GTEx/v6_GTEx_Analysis_2015-01-12/eqtl_data/GTEx_Analysis_2015-01-12_eQTLInputFiles_geneLevelNormalizedExpressionMatrices.tar.gz .
     mkdir -p expr
     tar xf GTEx_Analysis_2015-01-12_eQTLInputFiles_geneLevelNormalizedExpressionMatrices.tar.gz -C expr
     parallel --halt=now,fail=1 -X gzip ::: expr/*.txt
   #+END_SRC

   #+RESULTS:
   : 11563180

   #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar/fqtl/expr/
     qsub -cwd -V -terse -j y
     function z () { zcat $1 | awk -vf=$(basename $1 _Analysis.expr.txt.gz) 'NR == 1 {n = NF - 1} END {print f, n, NR - 1; exit}'; }
     export -f z
     parallel -j1 z ::: *.expr.txt.gz | awk 'BEGIN {print "tissue", "num_samples", "num_genes"} {print}' >sample-sizes.txt
   #+END_SRC

   #+RESULTS:
   : 11576647

   #+BEGIN_SRC ipython
     sample_sizes = pd.read_csv('/broad/hptmp/aksarkar/fqtl/expr/sample-sizes.txt', sep=' ')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[4]:
   :END:

   Read the GTEx tissue colors.

   #+BEGIN_SRC ipython
     colors = pd.read_csv('/broad/compbio/aksarkar/projects/gtex-fqtl/data/tissues.colors.txt', header=None, sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   :END:

   Parse the ~fqtl~ results.

   #+BEGIN_SRC ipython
     def unpack(X):
       if '|' in X.iloc[3]:
         T = pd.DataFrame(it.zip_longest(*X.apply(lambda x: str(x).split('|')).values, fillvalue=np.nan))
         T.columns = X.index
         T.fillna(T.iloc[0], inplace=True)
         return T
       else:
         return X.to_frame().T
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[6]:
   :END:

   #+BEGIN_SRC ipython :async t
     fqtl_res = pd.concat([pd.read_csv(f'/broad/compbio/aksarkar/projects/gtex-fqtl/result/stat/chr{i}/50/combined.txt.gz', header=None, sep='\t') for i in range(1, 23)])
     fqtl_res.columns = ['gene', 'chr', 'tss', 'tissue_idx', 'tissue_name', 'tissue_theta', 'tissue_se', 'tissue_lodds', 'snp_name', 'snp_theta', 'snp_se', 'snp_lodds', 'factor', 'pip']
     fqtl_res = pd.concat([unpack(x) for _, x in fqtl_res[fqtl_res['pip'] == 0.95].iterrows()])
     fqtl_res.to_csv('/broad/compbio/aksarkar/projects/gtex-fqtl/result/stat/fqtl-combined.txt.gz', sep='\t', compression='gzip')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[107]:
   :END:

   Read the ~fqtl~ results.

   #+BEGIN_SRC ipython
     fqtl_res = pd.read_csv('/broad/compbio/aksarkar/projects/gtex-fqtl/result/stat/fqtl-combined.txt.gz', sep='\t', index_col=0)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   :END:

   Count how many genes we retained at least one factor/loading pair for.

   #+BEGIN_SRC ipython
     len(fqtl_res['gene'].unique())
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[8]:
   : 20433
   :END:

** Relationship of sample size to number of eGenes
   :PROPERTIES:
   :CUSTOM_ID: egenes
   :END:

   Read the univariate eGenes (\(q < 0.05\)).

   #+BEGIN_SRC ipython
     univariate_res = {os.path.basename(f[:-24]): pd.read_csv(f, sep='\t') for f in glob.glob('/broad/hptmp/aksarkar/fqtl/egenes-filtered/*.filteredEGenes')}
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[8]:
   :END:

   Read the list of genes for which we fit ~fqtl~ models.

   #+BEGIN_SRC ipython
     valid_genes = pd.concat([pd.read_csv(f'/broad/compbio/aksarkar/projects/gtex-fqtl/data/fqtl-{i}-valid.genes.txt', sep='\t', header=None) for i in range(1, 23)])
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   :END:

   Plot the relationship between eGenes and sample size.

   #+BEGIN_SRC ipython
     fqtl_egenes = fqtl_res.groupby('tissue_name')['gene'].agg(lambda x: len(set(x)))
     univariate_egenes = pd.DataFrame.from_dict({k: univariate_res[k].shape[0] for k in univariate_res}, orient='index')
     J = (sample_sizes
          .merge(colors, left_on='tissue', right_on=0)
          .merge(fqtl_egenes, left_on='tissue', right_on='tissue_name')
          .merge(univariate_egenes, left_on='tissue', right_index=True)
          .rename({'gene': 'fqtl', '0_y': 'univariate', 1: 'color'}, axis='columns'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[37]:
   :END:

   # TODO: https://matplotlib.org/gallery/text_labels_and_annotations/custom_legends.html

   #+BEGIN_SRC ipython :ipyfile figure/analysis.org/egenes-vs-sample-size.png
     plt.clf()
     plt.gcf().set_size_inches(4, 3)
     for _, row in J.iterrows():
       base = row['univariate']
       top = row['fqtl']
       plt.scatter(row['num_samples'], base, c=f'{row["color"]}', s=8, marker='.')
       plt.scatter(row['num_samples'], top, c=f'{row["color"]}', s=8, marker='^')
       plt.arrow(row['num_samples'], base, 0, top - base, lw=1, color=f'{row["color"]}')
     plt.xlabel('Sample size')
     plt.ylabel('Number of discovered eGenes')
     plt.ylim(0, 11000)
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[43]:
   [[file:figure/analysis.org/egenes-vs-sample-size.png]]
   :END:

   fQTL finds more eGenes in brain tissues, but appears to over-regularize
   tissues with larger sample sizes. This is in constrast to what we observe in
   applying fQTL to GTEx v8.

* Tissue-specific TWAS
  :PROPERTIES:
  :CUSTOM_ID: twas
  :END:
** Pre-process the summary statistics

   The GTEx consortium provided summary statistics in hg38. LiftOver back to
   hg19 to combine with v6p models.

   #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar
     find gtex_gwas_hg38_tabix/ -name "*.bed.gz" >manifest
     qsub -cwd -terse -V -sync n -j y -N liftover -S /bin/bash -t 1-114
     set -e
     function lift () {
         in=gtex-gwas-hg19/$(basename $1 .bed.gz).hg38
         zcat $1 | awk -vOFS='\t' 'NR > 1 {print $1, $2, $3, $4"|"$5"|"$6"|"$7}' >$in
         out=gtex-gwas-hg19/$(basename $1 .bed.gz).hg19
         liftOver $in /broad/compbio/data/gtex_eqtl_tabix/hg38ToHg19.over.chain.gz $out $out.unmapped
         sort -k1,1 -k2,2n $out | tr '|' '\t' | bgzip >gtex-gwas-hg19/$(basename $1)
         tabix gtex-gwas-hg19/$(basename $1)
     }
     readarray -O1 tasks <manifest
     lift ${tasks[$SGE_TASK_ID]}
   #+END_SRC

   #+RESULTS:
   : 11694381.1-114:1

** AD replication data

  Download ADGC phase 2 (https://www.niagads.org/datasets/ng00076)

  #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar
    curl -sL "https://www.niagads.org/system/tdf/public_docs/ADGC2_ModelB_METAL_COMMON.InvVar.results.formatted_p-value_only.txt?file=1&type=field_collection_item&id=100&force=" -o adgc2.txt
    gzip adgc2.txt
  #+END_SRC

  The data is on hg37.

  #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar
    zcat adgc2.txt.gz | awk 'NR == 2 {split($1, a, ":"); print a[2]; exit}' | xargs -I{} zgrep -wm1 {} /broad/compbio/lward/incoming/dbSNP/hg19_b137/bed_chr_1.txt.gz
  #+END_SRC

  #+RESULTS:
  | chr1 | 100000012 | 100000012 | rs10875231 |   | + | 224514623 | GRCh37.p5,reference | G/T | genomic | snp | byFrequency |   |   | unknown | exact | 2 |   | 14 | 1000GENOMES,ABI,BCM-HGSC-SUB,BGI,BUSHMAN,COMPLETE_GENOMICS,CSHL-HAPMAP,ENSEMBL,GMI,HGSV,ILLUMINA-UK,PERLEGEN,PJP,SC_SNP | 1 | T | 2184 | 0.3086 | submitter_linkout,1,assembly_specific,MAF>5%_in_1+population,MAF>5%_in_all_population,double_hit_by_Mullikin |   | 120 | 137 | unknown |

  The publicly available data does not have \(z\)-scores or odds ratios.

  Download GWAX (https://www.nature.com/articles/ng.3766)

  #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar/
    qsub -terse -cwd -V -j y -sync n
    curl -sOL "http://gwas-browser.nygenome.org/downloads/gwas-browser/AD.gwax.assoc.gz"
  #+END_SRC

  #+RESULTS:
  : 11674089

  The data is on hg37.

  #+BEGIN_SRC shell
    zgrep -wm1 rs144155419 /broad/compbio/lward/incoming/dbSNP/hg19_b137/bed_chr_1.txt.gz
  #+END_SRC

  #+RESULTS:
  | chr1 | 717587 | 717587 | rs144155419 |   | + | 224514624 | GRCh37.p5,reference | A/G | genomic | snp | by1000G | 0 | 0 | unknown | exact | 2 |   | 1 | 1000GENOMES | 1 | A | 2184 | 0.0064 | 1,assembly_specific |   | 134 | 134 | unknown |

  Convert \(p\)-values to \(z\)-scores and format the data.

  #+BEGIN_SRC ipython :async t
    data = pd.read_csv('/broad/hptmp/aksarkar/AD.gwax.assoc.gz', sep=' ')
    data['chr'] = data['CHR'].apply(lambda x: f'chr{x}')
    data['start'] = data['BP']
    # Important: we removed indels from GTEx
    data['end'] = data.apply(lambda x: x['BP'] if len(x['A1']) == len(x['A2']) == 1 else np.nan, axis=1).astype('Int64')
    data['zscore'] = np.sqrt(st.chi2(1).sf(data['P'])) * np.sign(np.log(data['OR']))
    data['pval'] = data['P']
    (data[['chr', 'start', 'end', 'A1', 'A2', 'zscore', 'pval']]
     .dropna()
     .rename({'A1': 'a1', 'A2': 'a2'})
     .to_csv('/broad/hptmp/aksarkar/gtex-gwas-hg19/ad-gwax-hg37.bed.gz', sep='\t', compression='gzip'))
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[10]:
  :END:

** Prepare the genotype matrices

   Extract genotypes within 1 megabase of the TSS for each gene. Genes are
   indexed in the manifest.

   #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar/geno/
     awk '$6 >= 10' /broad/compbio/aksarkar/projects/gtex-fqtl/data/fqtl-*-valid.genes.txt >manifest
     qsub -cwd -V -terse -sync n -j y -N plink -t 2-100 -l h_vmem=2G
     awk -vn=$SGE_TASK_LAST -vi=$SGE_TASK_ID 'NR % n == i - 1 {w = 1000000; ub = $4 + w; if ($4 > w) {lb = $4 - w} else {lb = 0} system("plink --memory 2000 --bfile /broad/compbio/data/GTEx/GTEx_restricted/v6_plink/BED_qc/chr"$3" --make-bed --chr "$3" --from-bp "lb" --to-bp "ub" --out "$1)}' manifest
   #+END_SRC

   #+RESULTS:
   : 11696455.2-100:1

** Develop TWAS implementation

   #+BEGIN_SRC ipython
     prefix = '/broad/compbio/ypp/gtex/analysis/fqtl-gtex/result/fqtl-std/1002/50'
     snp_annot = pd.read_csv(f'{prefix}/fqtl.snp.info.gz', sep='\t', header=None)
     tis_annot = pd.read_csv(f'{prefix}/fqtl.tis.info.gz', sep='\t', header=None)
     snp_lodds = pd.read_csv(f'{prefix}/fqtl.snp.lodds.txt.gz', sep='\t', header=None)
     keep = (sp.expit(snp_lodds) > .95).any(axis=0)
     L = pd.read_csv(f'{prefix}/fqtl.snp.theta.txt.gz', sep='\t', header=None)
     L.index = snp_annot[3]
     F = pd.read_csv(f'{prefix}/fqtl.tis.theta.txt.gz', sep='\t', header=None)
     F.index = tis_annot[1].apply(lambda x: x[:-9])
     B = L.loc[:,keep].dot(F.loc[:,keep].T)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[29]:
   :END:

   #+BEGIN_SRC ipython
     import pyplink
     with pyplink.PyPlink('/broad/hptmp/aksarkar/geno/1002') as f:
       fam = f.get_fam()
       bim = f.get_bim()
       x = np.ma.masked_equal(np.array([row for _, row in f.iter_geno()]).T, -1).astype(float)
       x -= x.mean()
       x /= x.std()
       x = pd.DataFrame(x, index=fam['fid'], columns=bim['pos'])
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   :END:

   #+BEGIN_SRC ipython
     u, d, vt = np.linalg.svd(x, full_matrices=False)
     (d > 1e-8).sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[93]:
   : 450
   :END:

   #+BEGIN_SRC ipython
     genes = pd.read_csv('/broad/hptmp/aksarkar/geno/manifest', sep='\t', header=None, index_col=0)
     f = tabix.open('/broad/hptmp/aksarkar/gtex-gwas-hg19/imputed_IGAP_Alzheimer.bed.gz')
     row = genes.loc[1002]
     gwas_z = (pd.DataFrame(f.query(f'chr{row[2]}', int(row[3] - 1e6), int(row[3] + 1e6)))
               .astype(dict(enumerate([str, int, int, str, str, float, float]))))
     gwas_z.head()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[131]:
   #+BEGIN_EXAMPLE
     0         1         2  3     4       5       6
     0  chr1  31083477  31083478  G     A -1.3432  0.1790
     1  chr1  31083729  31083730  A  ATCT -1.6553  0.0979
     2  chr1  31083985  31083986  T     C -1.4981  0.1340
     3  chr1  31084179  31084180  A     G  1.7782  0.0754
     4  chr1  31084233  31084234  T     A -1.6000  0.1100
   #+END_EXAMPLE
   :END:

   #+BEGIN_SRC ipython
     twas_data = gwas_z.merge(snp_annot, left_on=[2, 3, 4], right_on=[3, 4, 5]).set_index('2_x')
     twas_data.head(n=1)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[133]:
   #+BEGIN_EXAMPLE
     2  3  4   0_x       1_x 3_x 4_x     5_x      6  0_y  \
     2_x
     31083478  31083478  G  A  chr1  31083477   G   A -1.3432  0.179    1

     1_y  2_y       3_y 4_y 5_y
     2_x
     31083478  1_31083478_A_G_b37    0  31083478   G   A
   #+END_EXAMPLE
   :END:

   #+BEGIN_SRC ipython
     bt = B.loc[twas_data['3_y'], 'Artery_Tibial']
     z = twas_data['5_x']
     X = x.loc[:,twas_data['3_y']]
     R = X.T.dot(X) / x.shape[0]
     twas(bt, z, R)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[130]:
   : 0.4641751949731608
   :END:

   #+BEGIN_SRC ipython
   #+END_SRC

** Run TWAS

   #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar/
     qsub -cwd -V -terse -j y -sync n -N twas -l h_vmem=4G,h_rt=12:00:00
     source activate /broad/compbio/aksarkar/.conda/envs/fqtl 
     python /broad/compbio/aksarkar/projects/gtex-fqtl/twas.py /broad/hptmp/aksarkar/gtex-gwas-hg19/imputed_IGAP_Alzheimer.bed.gz twas/IGAP_Alzheimer.txt.gz
   #+END_SRC

   #+RESULTS:
   : 11778533

** Read the TWAS summary statistics

   For each trait, assign each gene/mechanism to the best LD block.

   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/assign-twas.py
     <<imports>>
     import os
     i = os.environ['SLURM_ARRAY_TASK_ID']
     (pd.read_csv(f'/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/docs/share/twas/chr{i}.twas.bed.gz', sep='\t')
      .groupby(['trait', 'ensg', 'factor'])
      .apply(lambda x: x.loc[np.abs(x['z']).idxmax])
      .reset_index(drop=True)
      .to_csv(f'/broad/hptmp/aksarkar/fqtl/twas/chr{i}-twas.txt.gz', compression='gzip', sep='\t', index=None))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[7]:
   :END:

   #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar/fqtl/twas/
     sbatch --partition=broadwl --mem=8G --time=40:00 --job-name=assign-twas -a 1
     #!/bin/bash
     source activate fqtl
     module load htslib
     module load plink
     python /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/assign-twas.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 58196600

   Extract the significant hits.

   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/extract-twas.py
     <<imports>>
     def bh(chunk, key, alpha=0.05):
       N = chunk.shape[0]
       temp = chunk.sort_values(key)
       keep = temp[key] < alpha * np.arange(1, N + 1) / N
       return temp[keep]
     twas_sig = (pd.concat([pd.read_csv(f'/broad/hptmp/aksarkar/fqtl/twas/chr{i}-twas.txt.gz', sep='\t') for i in range(1, 23)])
                 .groupby(['trait'])
                 .apply(bh, key='p.val')
                 .reset_index(drop=True))
     twas_sig.to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-significant.txt.gz', compression='gzip', sep='\t')
   #+END_SRC

   #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar/fqtl/twas/
     sbatch --partition=broadwl --mem=32G --time=10:00 --job-name=extract-twas
     #!/bin/bash
     source activate fqtl
     module load htslib
     module load plink
     python /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/extract-twas.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 58197867

   Read the significant hits.

   #+NAME: read-twas-sig
   #+BEGIN_SRC ipython
     twas_sig = pd.read_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-significant.txt.gz', sep='\t', index_col=0)
   #+END_SRC

   #+RESULTS: read-twas-sig
   :RESULTS:
   # Out[7]:
   :END:

** Plotting code

   Reorder matrix columns to get similar columns next to each other.

   #+BEGIN_SRC ipython
     def newick(children, root, N):
       if root < N:
         return [root]
       else:
         left, right = children[root - N]
         res = newick(children, left, N)
         res.extend(newick(children, right, N))
         return res

     def order(L):
       N = L.shape[0]
       m0 = sklearn.cluster.AgglomerativeClustering(compute_full_tree=True).fit(L)
       return newick(m0.children_, 2 * (N - 1), N)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   :END:

** Descriptive statistics
   :PROPERTIES:
   :CUSTOM_ID: twas-descriptive
   :END:

   Count the total number of trait-gene associations.

   #+BEGIN_SRC ipython
     twas_sig.groupby(['trait', 'ensg']).first().shape[0]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[30]:
   : 31551
   :END:

   Plot the distribution of associations per trait.

   #+BEGIN_SRC ipython :ipyfile figure/analysis.org/twas-per-trait.png
     genes_per_trait = twas_sig.groupby('trait')['ensg'].agg(lambda x: len(set(x))).reset_index()
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.hist(genes_per_trait['ensg'], bins=20, color='k', density=True)
     plt.xlabel('Number of associated genes')
     plt.ylabel('Density')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[32]:
   : Text(0, 0.5, 'Density')
   [[file:figure/analysis.org/twas-per-trait.png]]
   :END:

   Count the number of gene associations with more than one mechanism.

   #+BEGIN_SRC ipython
     twas_sig.groupby(['trait', 'ensg'])['factor'].apply(lambda x: len(set(x)) > 1).sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[33]:
   : 10931
   :END:

   Plot the distribution of number of gene-factor associations across traits.

   #+BEGIN_SRC ipython
     gene_factor_assoc = twas_sig.groupby(['trait', 'ensg'])['factor'].agg(len).reset_index()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/analysis.org/gene-factor-dist.png
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.hist(gene_factor_assoc['factor'], bins=gene_factor_assoc['factor'].max() - 1, color='k', density=True)
     plt.xlabel('Number of associated mechanisms')
     plt.ylabel('Density')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   : Text(0, 0.5, 'Density')
   [[file:figure/analysis.org/gene-factor-dist.png]]
   :END:

   Plot the distribution of average between mechanism LD for genes where
   multiple factors were associated.

   #+BEGIN_SRC ipython :async t
     between_ld = (gene_factor_assoc
                   .reset_index()
                   .apply(lambda x: ld_distribution.loc[x['ensg'], 'between'].max() if x['ensg'] in ld_distribution.index and x['factor'] > 1 else 0, axis=1))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[46]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/analysis.org/ind-mechs-per-gene.png
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.hist(between_ld, bins=10, color='k', density=True)
     plt.xlabel('Between mechanism LD $r^2$')
     plt.ylabel('Density')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[47]:
   : Text(0, 0.5, 'Density')
   [[file:figure/analysis.org/ind-mechs-per-gene.png]]
   :END:
   
   Count the proportion of genes with independent mechanisms (\(r^2 < 0.1\)).

   #+BEGIN_SRC ipython
     (between_ld < 0.1).sum() / between_ld.shape[0]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[49]:
   : 0.8699388577385816
   :END:

** Comparison to whole blood TWAS
   :PROPERTIES:
   :CUSTOM_ID: whole-blood-twas
   :END:

   Count the number of TWAS associations driven by mechanisms with high
   posterior probability on whole blood.

   #+BEGIN_SRC ipython
     blood_twas_sig = (fqtl_tis
      .merge(keep_gene_factors)
      .query('tis == "Whole_Blood"')
      .query('lodds > 2.94')
      [['ensg', 'factor', 'ld']]
      .merge(twas_sig, left_on=['ensg', 'factor', 'ld'], right_on=['ensg', 'factor', 'ld.idx']))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[59]:
   :END:

   #+BEGIN_SRC ipython
     blood_twas_sig.shape[0]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[60]:
   : 12321
   :END:

   Look at the traits with blood TWAS genes.

   #+BEGIN_SRC ipython
     len(set(blood_twas_sig['trait']))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[63]:
   : 113
   :END:

** GOM of TWAS

   #+BEGIN_SRC ipython
     B = (~np.isnan(twas_sig.pivot_table(index='trait', columns='ensg', values='z'))).astype(int)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[8]:
   :END:

   #+BEGIN_SRC ipython :async t
     obj = np.inf
     opt = None
     for trial in range(10):
       m = skd.NMF(n_components=15, beta_loss=1, solver='mu', init='random', l1_ratio=1, alpha=1).fit(B)
       if m.reconstruction_err_ < obj:
         opt = m
         obj = m.reconstruction_err_
     L = opt.transform(B)
     F = opt.components_
     L *= F.sum(axis=1)
     L /= L.sum(axis=1, keepdims=True)
     F /= F.sum(axis=1, keepdims=True)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[214]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/analysis.org/nmf.png
     plt.clf()
     plt.gcf().set_size_inches(7, 5)
     W = L.T[:,order(L)]
     plt.imshow(W[np.argsort(W.argmax(axis=1))], cmap=colorcet.cm['blues'], vmin=0, vmax=1)
     plt.xlabel('Traits')
     plt.xticks([])
     plt.ylabel('Modules')
     plt.yticks([])
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[215]:
   : ([], <a list of 0 Text yticklabel objects>)
   [[file:figure/analysis.org/nmf.png]]
   :END:

   Report the trait modules.

   #+BEGIN_SRC ipython
     (pd.concat({i: pd.DataFrame.from_dict({'trait': B.index[L[:,i] > .5], 'loading': L[:,i][L[:,i] > .5]}) for i in range(L.shape[1])})
      .to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/nmf.txt.gz', sep='\t'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[31]:
   :END:

   Report the gene modules.

   #+BEGIN_SRC ipython
     def top_genes(topics, num_genes=100):
       res = {}
       for k, t in topics.iteritems():
         # Dey et al. Eq. 3-4 https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1006599
         kl = t.values.reshape(-1, 1) * np.log((t.values.reshape(-1, 1) + 1e-8) / (topics.values + 1e-8)) + topics.values - t.values.reshape(-1, 1)
         kl = np.delete(kl, k, axis=1)
         res[k] = pd.DataFrame(kl, index=B.columns).min(axis=1).sort_values(ascending=False).head(n=num_genes)
       return pd.concat(res).reset_index()
   #+END_SRC

   #+BEGIN_SRC ipython
     res = top_genes(pd.DataFrame(F.T, index=B.columns), num_genes=100)
     res.to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-gom-topics.txt.gz', compression='gzip', sep='\t', index=None)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[179]:
   :END:

   Compute pathway enrichments for the gene modules using PANTHER.

   #+BEGIN_SRC bash
     function z {
         zcat /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-gom-topics.txt.gz | \
             awk -vm=$1 '$1 == m {print $2}' | \
             curl -s http://www.pantherdb.org/webservices/garuda/tools/enrichment/VER_2/enrichment.jsp -F organism="Homo sapiens" -F geneList=@- -F enrichmentType=fullGO_process -F type=enrichment -F correction=FDR >/broad/hptmp/aksarkar/fqtl/twas/panther-topic-$1.txt
     }
     export -f z
     parallel -j5 z ::: $(seq 0 14)
   #+END_SRC

   #+RESULTS:

   Read the pathway enrichments.

   #+BEGIN_SRC ipython
     panther_results = (pd.concat([pd.read_csv(f'/broad/hptmp/aksarkar/fqtl/twas/panther-topic-{i}.txt', sep='\t', index_col=None)
                                  for i in range(topics.shape[1])], keys=range(topics.shape[1]))
                        .reset_index(level=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[174]:
   :END:

   #+BEGIN_SRC ipython
     panther_results.to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-gom-pathways.txt.gz', sep='\t', index=None)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[175]:
   :END:

   #+BEGIN_SRC ipython
     (panther_results[panther_results['FDR'] < 0.05]
      .groupby('level_0')
      .apply(lambda x: pd.Series(list(set(x['Name']))))
      .reset_index(level=1, drop=True)
      .to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-gom-pathways-fdr-05.txt.gz', sep='\t', header=True))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[165]:
   :END:

** Sparse factor analysis of TWAS
   :PROPERTIES:
   :CUSTOM_ID: factor-analysis
   :END:

   Construct the matrix of TWAS association \(z\)-scores for genes with at
   least one significant hit. Take the best \(z\)-score across mechanisms and
   LD blocks.

   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/extract-twas-z.py
     <<imports>>
     <<read-twas-sig>>
     twas = pd.concat([pd.read_csv(f'/broad/hptmp/aksarkar/fqtl/twas/chr{i}-twas.txt.gz', sep='\t') for i in range(1, 23)])
     Z = (twas[twas['ensg'].isin(set(twas_sig['ensg']))]
          .groupby(['ensg', 'trait'])
          .apply(lambda x: x.loc[np.abs(x['z']).idxmax])['z']
          .reset_index()
          .pivot_table(index='ensg', columns='trait', values='z'))
     Z.to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-z-matrix.txt.gz', compression='gzip', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[7]:
   :END:

   #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar/fqtl/twas/
     sbatch --partition=broadwl --mem=16G --job-name=extract-twas-z
     #!/bin/bash
     source activate fqtl
     python /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/extract-twas-z.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 58222818

   Fit ~flash~.

   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/apply-flash.py
     <<imports>>
     <<r-imports>>
     Z = pd.read_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-z-matrix.txt.gz', sep='\t', index_col=0)
     data = flashr.flash_set_data(Z.values)
     fit = flashr.flash(data, var_type='constant', backfit=True)
     with open('flash-result.pkl', 'wb') as f:
       pickle.dump(fit, f)
   #+END_SRC

   #+BEGIN_SRC shell :dir :dir /broad/hptmp/aksarkar/fqtl/
     sbatch --partition=broadwl -n1 -c28 --exclusive --mem=16G --time=4:00:00 --job-name=flash
     #!/bin/bash
     source activate fqtl
     module load htslib
     module load plink
     python /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/apply-flash.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 58222919

   Read the results.

   #+BEGIN_SRC ipython
     Z = pd.read_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-z-matrix.txt.gz', sep='\t', index_col=0)
     # Explicitly call numpy2ri instead of pandas2ri because flashr doesn't support
     # data frames: https://github.com/stephenslab/flashr/issues/94
     data = flashr.flash_set_data(rpy2.robjects.numpy2ri.numpy2ri(Z.values))
     with open('/broad/hptmp/aksarkar/fqtl/flash-result.pkl', 'rb') as f:
       fit = pickle.load(f)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[180]:
   :END:

   Count the number of factors.

   #+BEGIN_SRC ipython
     K = np.array(fit[0])
     K
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[188]:
   : array([47], dtype=int32)
   :END:

   Recover the modules.

   #+BEGIN_SRC ipython
     Z = pd.read_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-z-matrix.txt.gz', sep='\t', index_col=0)
     gene_modules = pd.DataFrame(np.array(fit[3].rx2('l')), index=Z.index)
     trait_modules = pd.DataFrame(np.array(fit[3].rx2('f')), index=Z.columns)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[189]:
   :END:

   Estimate lfsr for the factors and loadings.

   #+BEGIN_SRC ipython :async t
     M = 5000
     T = flashr.flash_f_sampler(data, fit[fit.names.index('fit')], np.arange(1, K + 1))(M)
     trait_pr_pos = np.stack([np.sign(np.array(T[i])) == 1] for i in range(M)).mean(axis=0).reshape(trait_modules.shape)
     trait_pr_neg = np.stack([np.sign(np.array(T[i])) == -1] for i in range(M)).mean(axis=0).reshape(trait_modules.shape)
     trait_lfsr = np.fmin(trait_pr_pos, trait_pr_neg)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[190]:
   :END:

   #+BEGIN_SRC ipython
     pd.DataFrame(trait_lfsr, index=Z.columns).to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-trait-lfsr.txt.gz', sep='\t', compression='gzip')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[195]:
   :END:

   #+BEGIN_SRC ipython
     trait_lfsr = pd.read_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-trait-lfsr.txt.gz', sep='\t').values
   #+END_SRC

   Report the trait modules.

   #+BEGIN_SRC ipython
     (pd.concat({i: trait_modules[i][trait_lfsr[:,i] < 0.01] for i in range(trait_modules.shape[1])})
      .reset_index()
      .groupby('level_0')
      .apply(lambda x: x.loc[x[0].abs().sort_values(ascending=False).index])
      .reset_index(drop=True)
      .to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-trait-modules.txt.gz', compression='gzip', sep='\t'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[196]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/analysis.org/flashr-trait-modules.png
     plt.clf()
     plt.gcf().set_size_inches(7, 5)
     W = np.where(trait_lfsr < 0.01, trait_modules, 0)
     module_order = order(W.T)
     trait_order = np.argsort(np.abs(W[:,module_order]).argmax(axis=1))
     plt.imshow(W.T[:,trait_order][module_order], cmap=colorcet.cm['coolwarm'], vmin=-1, vmax=1)
     cb = plt.colorbar(shrink=0.35)
     cb.set_label('Normalized loading')
     plt.xlabel('Traits')
     plt.xticks([])
     plt.ylabel('Modules')
     plt.yticks([])
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[203]:
   [[file:figure/analysis.org/flashr-trait-modules.png]]
   :END:

   Report the gene modules.

   #+BEGIN_SRC ipython
     (pd.concat({i: gene_modules[i][np.abs(gene_modules[i]) > 0.05] for i in range(gene_modules.shape[1])})
      .reset_index()
      .groupby('level_0')
      .apply(lambda x: x.loc[x[0].abs().sort_values(ascending=False).index])
      .reset_index(drop=True)
      .to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-gene-modules.txt.gz', compression='gzip', sep='\t'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[51]:
   :END:

   Compute pathway enrichments for the gene modules using PANTHER.

   #+BEGIN_SRC bash
     function z {
         zcat /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-gene-modules.txt.gz | \
             awk -vm=$1 '$2 == m {print $3}' | \
             curl -s http://www.pantherdb.org/webservices/garuda/tools/enrichment/VER_2/enrichment.jsp -F organism="Homo sapiens" -F geneList=@- -F enrichmentType=fullGO_process -F type=enrichment -F correction=FDR >/broad/hptmp/aksarkar/fqtl/twas/panther-module-$1.txt
     }
     export -f z
     z 0
   #+END_SRC

   #+RESULTS:

   Read the pathway enrichments.

   #+BEGIN_SRC ipython
     panther_results = (pd.concat([pd.read_csv(f'/broad/hptmp/aksarkar/fqtl/twas/panther-module-{i}.txt', sep='\t', index_col=None)
                                  for i in range(47)], keys=range(47))
                        .reset_index(level=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[107]:
   :END:

   #+BEGIN_SRC ipython
     panther_results.to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-pathways.txt.gz', sep='\t', index=None)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[108]:
   :END:

   #+BEGIN_SRC ipython
     (panther_results[panther_results['FDR'] < 0.05]
      .groupby('level_0')
      .apply(lambda x: pd.Series(list(set(x['Name']))))
      .reset_index(level=1, drop=True)
      .to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-pathways-fdr-05.txt.gz', sep='\t', header=True))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[110]:
   :END:

** K-means clustering of TWAS

   #+BEGIN_SRC ipython
     Z = pd.read_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-z-matrix.txt.gz', sep='\t', index_col=0)
   #+END_SRC

   #+BEGIN_SRC ipython
   #+END_SRC

   #+BEGIN_SRC ipython
     m1 = sklearn.cluster.KMeans(n_clusters=20).fit(Z.T.fillna(0))
     pd.concat({i: pd.Series(Z.columns[m1.labels_ == i]) for i in range(m1.n_clusters)}).reset_index().to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-k-means.txt.gz', compression='gzip', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[280]:
   :END:

* References                                                       :noexport:

  - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5339290/
  - https://www.ncbi.nlm.nih.gov/pubmed/29022597

