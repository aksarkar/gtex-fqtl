#+TITLE: fQTL analysis
#+SETUPFILE: setup.org

* Introduction

  We previously fit ~fqtl~ models for 39,998 genes across 44 tissues from GTEx
  (version 6p). Here, we analyze the fitted ~fqtl~ models.

* Setup

  #+BEGIN_SRC emacs-lisp :exports none
    (org-babel-lob-ingest "/home/unix/aksarkar/.emacs.d/org-templates/library.org")
    (add-to-list 'python-shell-completion-native-disabled-interpreters "jupyter")
  #+END_SRC

  #+RESULTS:
  | jupyter | pypy | ipython |

  #+BEGIN_SRC emacs-lisp :exports none
    ;; This is needed to unjam when async tasks fail
    (ob-ipython--dequeue 'ob-ipython--async-queue)
  #+END_SRC

  #+RESULTS:

  #+CALL: ipython3(memory="16G",venv="fqtl") :dir /broad/hptmp/aksarkar/fqtl :exports none

  #+RESULTS:
  : 11753664

  #+NAME: imports
  #+BEGIN_SRC ipython
    import glob
    import itertools as it
    import os.path
    import numpy as np
    import pandas as pd
    import scipy.linalg as sl
    import scipy.special as sp
    import scipy.stats as st
  #+END_SRC

  #+RESULTS: imports
  :RESULTS:
  # Out[1]:
  :END:

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])
    import colorcet
    import matplotlib
    import matplotlib.pyplot as plt
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[2]:
  :END:

  #+BEGIN_SRC ipython
    plt.rcParams['font.family'] = 'Nimbus Sans'
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[3]:
  :END:

* Multi-tissue eQTL mapping
  :PROPERTIES:
  :CUSTOM_ID: gtex
  :END:
** Read the data

   Extract the GTEx univariate summary statistics.

   #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar/fqtl/
     qsub -cwd -V -terse -j y
     cp /broad/compbio/data/GTEx/v6_GTEx_Analysis_2015-01-12/eqtl_data/GTEx_Analysis_2015-01-12_eGenesFiltered.tar.gz .
     mkdir -p egenes-filtered
     tar xf GTEx_Analysis_2015-01-12_eGenesFiltered.tar.gz -C egenes-filtered
   #+END_SRC

   #+RESULTS:
   : 11562455

   Extract the gene expression matrices to get sample sizes.

   #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar/fqtl
     qsub -cwd -V -terse -j y
     cp /broad/compbio/data/GTEx/v6_GTEx_Analysis_2015-01-12/eqtl_data/GTEx_Analysis_2015-01-12_eQTLInputFiles_geneLevelNormalizedExpressionMatrices.tar.gz .
     mkdir -p expr
     tar xf GTEx_Analysis_2015-01-12_eQTLInputFiles_geneLevelNormalizedExpressionMatrices.tar.gz -C expr
     parallel --halt=now,fail=1 -X gzip ::: expr/*.txt
   #+END_SRC

   #+RESULTS:
   : 11563180

   #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar/fqtl/expr/
     qsub -cwd -V -terse -j y
     function z () { zcat $1 | awk -vf=$(basename $1 _Analysis.expr.txt.gz) 'NR == 1 {n = NF - 1} END {print f, n, NR - 1; exit}'; }
     export -f z
     parallel -j1 z ::: *.expr.txt.gz | awk 'BEGIN {print "tissue", "num_samples", "num_genes"} {print}' >sample-sizes.txt
   #+END_SRC

   #+RESULTS:
   : 11576647

   #+BEGIN_SRC ipython
     sample_sizes = pd.read_csv('/broad/hptmp/aksarkar/fqtl/expr/sample-sizes.txt', sep=' ')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[4]:
   :END:

   Read the GTEx tissue colors.

   #+BEGIN_SRC ipython
     colors = pd.read_csv('/broad/compbio/aksarkar/projects/gtex-fqtl/data/tissues.colors.txt', header=None, sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   :END:

   Parse the ~fqtl~ results.

   #+BEGIN_SRC ipython
     def unpack(X):
       if '|' in X.iloc[3]:
         T = pd.DataFrame(it.zip_longest(*X.apply(lambda x: str(x).split('|')).values, fillvalue=np.nan))
         T.columns = X.index
         T.fillna(T.iloc[0], inplace=True)
         return T
       else:
         return X.to_frame().T
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[6]:
   :END:

   #+BEGIN_SRC ipython :async t
     fqtl_res = pd.concat([pd.read_csv(f'/broad/compbio/aksarkar/projects/gtex-fqtl/result/stat/chr{i}/50/combined.txt.gz', header=None, sep='\t') for i in range(1, 23)])
     fqtl_res.columns = ['gene', 'chr', 'tss', 'tissue_idx', 'tissue_name', 'tissue_theta', 'tissue_se', 'tissue_lodds', 'snp_name', 'snp_theta', 'snp_se', 'snp_lodds', 'factor', 'pip']
     fqtl_res = pd.concat([unpack(x) for _, x in fqtl_res[fqtl_res['pip'] == 0.95].iterrows()])
     fqtl_res.to_csv('/broad/compbio/aksarkar/projects/gtex-fqtl/result/stat/fqtl-combined.txt.gz', sep='\t', compression='gzip')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[107]:
   :END:

   Read the ~fqtl~ results.

   #+BEGIN_SRC ipython
     fqtl_res = pd.read_csv('/broad/compbio/aksarkar/projects/gtex-fqtl/result/stat/fqtl-combined.txt.gz', sep='\t', index_col=0)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   :END:

   Count how many genes we retained at least one factor/loading pair for.

   #+BEGIN_SRC ipython
     len(fqtl_res['gene'].unique())
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[8]:
   : 20433
   :END:

** Relationship of sample size to number of eGenes
   :PROPERTIES:
   :CUSTOM_ID: egenes
   :END:

   Read the univariate eGenes (\(q < 0.05\)).

   #+BEGIN_SRC ipython
     univariate_res = {os.path.basename(f[:-24]): pd.read_csv(f, sep='\t') for f in glob.glob('/broad/hptmp/aksarkar/fqtl/egenes-filtered/*.filteredEGenes')}
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[8]:
   :END:

   Read the list of genes for which we fit ~fqtl~ models.

   #+BEGIN_SRC ipython
     valid_genes = pd.concat([pd.read_csv(f'/broad/compbio/aksarkar/projects/gtex-fqtl/data/fqtl-{i}-valid.genes.txt', sep='\t', header=None) for i in range(1, 23)])
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   :END:

   Plot the relationship between eGenes and sample size.

   #+BEGIN_SRC ipython
     fqtl_egenes = fqtl_res.groupby('tissue_name')['gene'].agg(lambda x: len(set(x)))
     univariate_egenes = pd.DataFrame.from_dict({k: univariate_res[k].shape[0] for k in univariate_res}, orient='index')
     J = (sample_sizes
          .merge(colors, left_on='tissue', right_on=0)
          .merge(fqtl_egenes, left_on='tissue', right_on='tissue_name')
          .merge(univariate_egenes, left_on='tissue', right_index=True)
          .rename({'gene': 'fqtl', '0_y': 'univariate', 1: 'color'}, axis='columns'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[37]:
   :END:

   # TODO: https://matplotlib.org/gallery/text_labels_and_annotations/custom_legends.html

   #+BEGIN_SRC ipython :ipyfile figure/analysis.org/egenes-vs-sample-size.png
     plt.clf()
     plt.gcf().set_size_inches(4, 3)
     for _, row in J.iterrows():
       base = row['univariate']
       top = row['fqtl']
       plt.scatter(row['num_samples'], base, c=f'{row["color"]}', s=8, marker='.')
       plt.scatter(row['num_samples'], top, c=f'{row["color"]}', s=8, marker='^')
       plt.arrow(row['num_samples'], base, 0, top - base, lw=1, color=f'{row["color"]}')
     plt.xlabel('Sample size')
     plt.ylabel('Number of discovered eGenes')
     plt.ylim(0, 11000)
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[43]:
   [[file:figure/analysis.org/egenes-vs-sample-size.png]]
   :END:

   fQTL finds more eGenes in brain tissues, but appears to over-regularize
   tissues with larger sample sizes. This is in constrast to what we observe in
   applying fQTL to GTEx v8.

   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[73]:
   : (0.8261525353495132, 4.855677357713278e-13)
   :END:

   Describe how many more eGenes ~fqtl~ discovers.

   #+BEGIN_SRC ipython
     (J['num_egenes_fqtl'] / J['num_egenes_snp']).describe()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[74]:
   #+BEGIN_EXAMPLE
     count    48.000000
     mean      2.263618
     std       0.308351
     min       1.636869
     25%       2.090294
     50%       2.175653
     75%       2.400919
     max       3.099417
     dtype: float64
   #+END_EXAMPLE
   :END:

* AD TWAS

* Tissue-specific TWAS
  :PROPERTIES:
  :CUSTOM_ID: twas
  :END:
** Read the TWAS summary statistics

   For each trait, assign each gene/mechanism to the best LD block.

   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/assign-twas.py
     <<imports>>
     import os
     i = os.environ['SLURM_ARRAY_TASK_ID']
     (pd.read_csv(f'/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/docs/share/twas/chr{i}.twas.bed.gz', sep='\t')
      .groupby(['trait', 'ensg', 'factor'])
      .apply(lambda x: x.loc[np.abs(x['z']).idxmax])
      .reset_index(drop=True)
      .to_csv(f'/broad/hptmp/aksarkar/fqtl/twas/chr{i}-twas.txt.gz', compression='gzip', sep='\t', index=None))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[7]:
   :END:

   #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar/fqtl/twas/
     sbatch --partition=broadwl --mem=8G --time=40:00 --job-name=assign-twas -a 1
     #!/bin/bash
     source activate fqtl
     module load htslib
     module load plink
     python /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/assign-twas.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 58196600

   Extract the significant hits.

   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/extract-twas.py
     <<imports>>
     def bh(chunk, key, alpha=0.05):
       N = chunk.shape[0]
       temp = chunk.sort_values(key)
       keep = temp[key] < alpha * np.arange(1, N + 1) / N
       return temp[keep]
     twas_sig = (pd.concat([pd.read_csv(f'/broad/hptmp/aksarkar/fqtl/twas/chr{i}-twas.txt.gz', sep='\t') for i in range(1, 23)])
                 .groupby(['trait'])
                 .apply(bh, key='p.val')
                 .reset_index(drop=True))
     twas_sig.to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-significant.txt.gz', compression='gzip', sep='\t')
   #+END_SRC

   #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar/fqtl/twas/
     sbatch --partition=broadwl --mem=32G --time=10:00 --job-name=extract-twas
     #!/bin/bash
     source activate fqtl
     module load htslib
     module load plink
     python /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/extract-twas.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 58197867

   Read the significant hits.

   #+NAME: read-twas-sig
   #+BEGIN_SRC ipython
     twas_sig = pd.read_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-significant.txt.gz', sep='\t', index_col=0)
   #+END_SRC

   #+RESULTS: read-twas-sig
   :RESULTS:
   # Out[7]:
   :END:

** Plotting code

   Reorder matrix columns to get similar columns next to each other.

   #+BEGIN_SRC ipython
     def newick(children, root, N):
       if root < N:
         return [root]
       else:
         left, right = children[root - N]
         res = newick(children, left, N)
         res.extend(newick(children, right, N))
         return res

     def order(L):
       N = L.shape[0]
       m0 = sklearn.cluster.AgglomerativeClustering(compute_full_tree=True).fit(L)
       return newick(m0.children_, 2 * (N - 1), N)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   :END:

** Descriptive statistics
   :PROPERTIES:
   :CUSTOM_ID: twas-descriptive
   :END:

   Count the total number of trait-gene associations.

   #+BEGIN_SRC ipython
     twas_sig.groupby(['trait', 'ensg']).first().shape[0]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[30]:
   : 31551
   :END:

   Plot the distribution of associations per trait.

   #+BEGIN_SRC ipython :ipyfile figure/analysis.org/twas-per-trait.png
     genes_per_trait = twas_sig.groupby('trait')['ensg'].agg(lambda x: len(set(x))).reset_index()
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.hist(genes_per_trait['ensg'], bins=20, color='k', density=True)
     plt.xlabel('Number of associated genes')
     plt.ylabel('Density')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[32]:
   : Text(0, 0.5, 'Density')
   [[file:figure/analysis.org/twas-per-trait.png]]
   :END:

   Count the number of gene associations with more than one mechanism.

   #+BEGIN_SRC ipython
     twas_sig.groupby(['trait', 'ensg'])['factor'].apply(lambda x: len(set(x)) > 1).sum()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[33]:
   : 10931
   :END:

   Plot the distribution of number of gene-factor associations across traits.

   #+BEGIN_SRC ipython
     gene_factor_assoc = twas_sig.groupby(['trait', 'ensg'])['factor'].agg(len).reset_index()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/analysis.org/gene-factor-dist.png
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.hist(gene_factor_assoc['factor'], bins=gene_factor_assoc['factor'].max() - 1, color='k', density=True)
     plt.xlabel('Number of associated mechanisms')
     plt.ylabel('Density')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[11]:
   : Text(0, 0.5, 'Density')
   [[file:figure/analysis.org/gene-factor-dist.png]]
   :END:

   Plot the distribution of average between mechanism LD for genes where
   multiple factors were associated.

   #+BEGIN_SRC ipython :async t
     between_ld = (gene_factor_assoc
                   .reset_index()
                   .apply(lambda x: ld_distribution.loc[x['ensg'], 'between'].max() if x['ensg'] in ld_distribution.index and x['factor'] > 1 else 0, axis=1))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[46]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/analysis.org/ind-mechs-per-gene.png
     plt.clf()
     plt.gcf().set_size_inches(3, 3)
     plt.hist(between_ld, bins=10, color='k', density=True)
     plt.xlabel('Between mechanism LD $r^2$')
     plt.ylabel('Density')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[47]:
   : Text(0, 0.5, 'Density')
   [[file:figure/analysis.org/ind-mechs-per-gene.png]]
   :END:
   
   Count the proportion of genes with independent mechanisms (\(r^2 < 0.1\)).

   #+BEGIN_SRC ipython
     (between_ld < 0.1).sum() / between_ld.shape[0]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[49]:
   : 0.8699388577385816
   :END:

** Comparison to whole blood TWAS
   :PROPERTIES:
   :CUSTOM_ID: whole-blood-twas
   :END:

   Count the number of TWAS associations driven by mechanisms with high
   posterior probability on whole blood.

   #+BEGIN_SRC ipython
     blood_twas_sig = (fqtl_tis
      .merge(keep_gene_factors)
      .query('tis == "Whole_Blood"')
      .query('lodds > 2.94')
      [['ensg', 'factor', 'ld']]
      .merge(twas_sig, left_on=['ensg', 'factor', 'ld'], right_on=['ensg', 'factor', 'ld.idx']))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[59]:
   :END:

   #+BEGIN_SRC ipython
     blood_twas_sig.shape[0]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[60]:
   : 12321
   :END:

   Look at the traits with blood TWAS genes.

   #+BEGIN_SRC ipython
     len(set(blood_twas_sig['trait']))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[63]:
   : 113
   :END:

** GOM of TWAS

   #+BEGIN_SRC ipython
     B = (~np.isnan(twas_sig.pivot_table(index='trait', columns='ensg', values='z'))).astype(int)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[8]:
   :END:

   #+BEGIN_SRC ipython :async t
     obj = np.inf
     opt = None
     for trial in range(10):
       m = skd.NMF(n_components=15, beta_loss=1, solver='mu', init='random', l1_ratio=1, alpha=1).fit(B)
       if m.reconstruction_err_ < obj:
         opt = m
         obj = m.reconstruction_err_
     L = opt.transform(B)
     F = opt.components_
     L *= F.sum(axis=1)
     L /= L.sum(axis=1, keepdims=True)
     F /= F.sum(axis=1, keepdims=True)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[214]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/analysis.org/nmf.png
     plt.clf()
     plt.gcf().set_size_inches(7, 5)
     W = L.T[:,order(L)]
     plt.imshow(W[np.argsort(W.argmax(axis=1))], cmap=colorcet.cm['blues'], vmin=0, vmax=1)
     plt.xlabel('Traits')
     plt.xticks([])
     plt.ylabel('Modules')
     plt.yticks([])
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[215]:
   : ([], <a list of 0 Text yticklabel objects>)
   [[file:figure/analysis.org/nmf.png]]
   :END:

   Report the trait modules.

   #+BEGIN_SRC ipython
     (pd.concat({i: pd.DataFrame.from_dict({'trait': B.index[L[:,i] > .5], 'loading': L[:,i][L[:,i] > .5]}) for i in range(L.shape[1])})
      .to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/nmf.txt.gz', sep='\t'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[31]:
   :END:

   Report the gene modules.

   #+BEGIN_SRC ipython
     def top_genes(topics, num_genes=100):
       res = {}
       for k, t in topics.iteritems():
         # Dey et al. Eq. 3-4 https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1006599
         kl = t.values.reshape(-1, 1) * np.log((t.values.reshape(-1, 1) + 1e-8) / (topics.values + 1e-8)) + topics.values - t.values.reshape(-1, 1)
         kl = np.delete(kl, k, axis=1)
         res[k] = pd.DataFrame(kl, index=B.columns).min(axis=1).sort_values(ascending=False).head(n=num_genes)
       return pd.concat(res).reset_index()
   #+END_SRC

   #+BEGIN_SRC ipython
     res = top_genes(pd.DataFrame(F.T, index=B.columns), num_genes=100)
     res.to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-gom-topics.txt.gz', compression='gzip', sep='\t', index=None)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[179]:
   :END:

   Compute pathway enrichments for the gene modules using PANTHER.

   #+BEGIN_SRC bash
     function z {
         zcat /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-gom-topics.txt.gz | \
             awk -vm=$1 '$1 == m {print $2}' | \
             curl -s http://www.pantherdb.org/webservices/garuda/tools/enrichment/VER_2/enrichment.jsp -F organism="Homo sapiens" -F geneList=@- -F enrichmentType=fullGO_process -F type=enrichment -F correction=FDR >/broad/hptmp/aksarkar/fqtl/twas/panther-topic-$1.txt
     }
     export -f z
     parallel -j5 z ::: $(seq 0 14)
   #+END_SRC

   #+RESULTS:

   Read the pathway enrichments.

   #+BEGIN_SRC ipython
     panther_results = (pd.concat([pd.read_csv(f'/broad/hptmp/aksarkar/fqtl/twas/panther-topic-{i}.txt', sep='\t', index_col=None)
                                  for i in range(topics.shape[1])], keys=range(topics.shape[1]))
                        .reset_index(level=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[174]:
   :END:

   #+BEGIN_SRC ipython
     panther_results.to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-gom-pathways.txt.gz', sep='\t', index=None)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[175]:
   :END:

   #+BEGIN_SRC ipython
     (panther_results[panther_results['FDR'] < 0.05]
      .groupby('level_0')
      .apply(lambda x: pd.Series(list(set(x['Name']))))
      .reset_index(level=1, drop=True)
      .to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-gom-pathways-fdr-05.txt.gz', sep='\t', header=True))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[165]:
   :END:

** Sparse factor analysis of TWAS
   :PROPERTIES:
   :CUSTOM_ID: factor-analysis
   :END:

   Construct the matrix of TWAS association \(z\)-scores for genes with at
   least one significant hit. Take the best \(z\)-score across mechanisms and
   LD blocks.

   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/extract-twas-z.py
     <<imports>>
     <<read-twas-sig>>
     twas = pd.concat([pd.read_csv(f'/broad/hptmp/aksarkar/fqtl/twas/chr{i}-twas.txt.gz', sep='\t') for i in range(1, 23)])
     Z = (twas[twas['ensg'].isin(set(twas_sig['ensg']))]
          .groupby(['ensg', 'trait'])
          .apply(lambda x: x.loc[np.abs(x['z']).idxmax])['z']
          .reset_index()
          .pivot_table(index='ensg', columns='trait', values='z'))
     Z.to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-z-matrix.txt.gz', compression='gzip', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[7]:
   :END:

   #+BEGIN_SRC shell :dir /broad/hptmp/aksarkar/fqtl/twas/
     sbatch --partition=broadwl --mem=16G --job-name=extract-twas-z
     #!/bin/bash
     source activate fqtl
     python /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/extract-twas-z.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 58222818

   Fit ~flash~.

   #+BEGIN_SRC ipython :eval never :noweb tangle :tangle /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/apply-flash.py
     <<imports>>
     <<r-imports>>
     Z = pd.read_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-z-matrix.txt.gz', sep='\t', index_col=0)
     data = flashr.flash_set_data(Z.values)
     fit = flashr.flash(data, var_type='constant', backfit=True)
     with open('flash-result.pkl', 'wb') as f:
       pickle.dump(fit, f)
   #+END_SRC

   #+BEGIN_SRC shell :dir :dir /broad/hptmp/aksarkar/fqtl/
     sbatch --partition=broadwl -n1 -c28 --exclusive --mem=16G --time=4:00:00 --job-name=flash
     #!/bin/bash
     source activate fqtl
     module load htslib
     module load plink
     python /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/apply-flash.py
   #+END_SRC

   #+RESULTS:
   : Submitted batch job 58222919

   Read the results.

   #+BEGIN_SRC ipython
     Z = pd.read_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-z-matrix.txt.gz', sep='\t', index_col=0)
     # Explicitly call numpy2ri instead of pandas2ri because flashr doesn't support
     # data frames: https://github.com/stephenslab/flashr/issues/94
     data = flashr.flash_set_data(rpy2.robjects.numpy2ri.numpy2ri(Z.values))
     with open('/broad/hptmp/aksarkar/fqtl/flash-result.pkl', 'rb') as f:
       fit = pickle.load(f)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[180]:
   :END:

   Count the number of factors.

   #+BEGIN_SRC ipython
     K = np.array(fit[0])
     K
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[188]:
   : array([47], dtype=int32)
   :END:

   Recover the modules.

   #+BEGIN_SRC ipython
     Z = pd.read_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-z-matrix.txt.gz', sep='\t', index_col=0)
     gene_modules = pd.DataFrame(np.array(fit[3].rx2('l')), index=Z.index)
     trait_modules = pd.DataFrame(np.array(fit[3].rx2('f')), index=Z.columns)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[189]:
   :END:

   Estimate lfsr for the factors and loadings.

   #+BEGIN_SRC ipython :async t
     M = 5000
     T = flashr.flash_f_sampler(data, fit[fit.names.index('fit')], np.arange(1, K + 1))(M)
     trait_pr_pos = np.stack([np.sign(np.array(T[i])) == 1] for i in range(M)).mean(axis=0).reshape(trait_modules.shape)
     trait_pr_neg = np.stack([np.sign(np.array(T[i])) == -1] for i in range(M)).mean(axis=0).reshape(trait_modules.shape)
     trait_lfsr = np.fmin(trait_pr_pos, trait_pr_neg)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[190]:
   :END:

   #+BEGIN_SRC ipython
     pd.DataFrame(trait_lfsr, index=Z.columns).to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-trait-lfsr.txt.gz', sep='\t', compression='gzip')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[195]:
   :END:

   #+BEGIN_SRC ipython
     trait_lfsr = pd.read_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-trait-lfsr.txt.gz', sep='\t').values
   #+END_SRC

   Report the trait modules.

   #+BEGIN_SRC ipython
     (pd.concat({i: trait_modules[i][trait_lfsr[:,i] < 0.01] for i in range(trait_modules.shape[1])})
      .reset_index()
      .groupby('level_0')
      .apply(lambda x: x.loc[x[0].abs().sort_values(ascending=False).index])
      .reset_index(drop=True)
      .to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-trait-modules.txt.gz', compression='gzip', sep='\t'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[196]:
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/analysis.org/flashr-trait-modules.png
     plt.clf()
     plt.gcf().set_size_inches(7, 5)
     W = np.where(trait_lfsr < 0.01, trait_modules, 0)
     module_order = order(W.T)
     trait_order = np.argsort(np.abs(W[:,module_order]).argmax(axis=1))
     plt.imshow(W.T[:,trait_order][module_order], cmap=colorcet.cm['coolwarm'], vmin=-1, vmax=1)
     cb = plt.colorbar(shrink=0.35)
     cb.set_label('Normalized loading')
     plt.xlabel('Traits')
     plt.xticks([])
     plt.ylabel('Modules')
     plt.yticks([])
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[203]:
   [[file:figure/analysis.org/flashr-trait-modules.png]]
   :END:

   Report the gene modules.

   #+BEGIN_SRC ipython
     (pd.concat({i: gene_modules[i][np.abs(gene_modules[i]) > 0.05] for i in range(gene_modules.shape[1])})
      .reset_index()
      .groupby('level_0')
      .apply(lambda x: x.loc[x[0].abs().sort_values(ascending=False).index])
      .reset_index(drop=True)
      .to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-gene-modules.txt.gz', compression='gzip', sep='\t'))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[51]:
   :END:

   Compute pathway enrichments for the gene modules using PANTHER.

   #+BEGIN_SRC bash
     function z {
         zcat /project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-gene-modules.txt.gz | \
             awk -vm=$1 '$2 == m {print $3}' | \
             curl -s http://www.pantherdb.org/webservices/garuda/tools/enrichment/VER_2/enrichment.jsp -F organism="Homo sapiens" -F geneList=@- -F enrichmentType=fullGO_process -F type=enrichment -F correction=FDR >/broad/hptmp/aksarkar/fqtl/twas/panther-module-$1.txt
     }
     export -f z
     z 0
   #+END_SRC

   #+RESULTS:

   Read the pathway enrichments.

   #+BEGIN_SRC ipython
     panther_results = (pd.concat([pd.read_csv(f'/broad/hptmp/aksarkar/fqtl/twas/panther-module-{i}.txt', sep='\t', index_col=None)
                                  for i in range(47)], keys=range(47))
                        .reset_index(level=0))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[107]:
   :END:

   #+BEGIN_SRC ipython
     panther_results.to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-pathways.txt.gz', sep='\t', index=None)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[108]:
   :END:

   #+BEGIN_SRC ipython
     (panther_results[panther_results['FDR'] < 0.05]
      .groupby('level_0')
      .apply(lambda x: pd.Series(list(set(x['Name']))))
      .reset_index(level=1, drop=True)
      .to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-pathways-fdr-05.txt.gz', sep='\t', header=True))
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[110]:
   :END:

** K-means clustering of TWAS

   #+BEGIN_SRC ipython
     Z = pd.read_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-z-matrix.txt.gz', sep='\t', index_col=0)
   #+END_SRC

   #+BEGIN_SRC ipython
   #+END_SRC

   #+BEGIN_SRC ipython
     m1 = sklearn.cluster.KMeans(n_clusters=20).fit(Z.T.fillna(0))
     pd.concat({i: pd.Series(Z.columns[m1.labels_ == i]) for i in range(m1.n_clusters)}).reset_index().to_csv('/project2/mstephens/aksarkar/projects/gtex_fqtl_2018/data/twas-k-means.txt.gz', compression='gzip', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[280]:
   :END:

* References                                                       :noexport:

  - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5339290/
  - https://www.ncbi.nlm.nih.gov/pubmed/29022597

